{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import optuna\n",
    "from steps.prepare_data import load_processed_data\n",
    "from utils.model import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Train----------\n",
      "\n",
      "Metrics\n",
      "AUC: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.96      0.98    140413\n",
      "         1.0       0.64      1.00      0.78      9585\n",
      "\n",
      "    accuracy                           0.96    149998\n",
      "   macro avg       0.82      0.98      0.88    149998\n",
      "weighted avg       0.98      0.96      0.97    149998\n",
      "\n",
      "-----------Test----------\n",
      "\n",
      "Metrics\n",
      "AUC: 0.89\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.96    140597\n",
      "         1.0       0.42      0.63      0.51      9403\n",
      "\n",
      "    accuracy                           0.92    150000\n",
      "   macro avg       0.70      0.79      0.73    150000\n",
      "weighted avg       0.94      0.92      0.93    150000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = load_processed_data()\n",
    "\n",
    "model_name = \"LightGbmV1_best.pickle\"\n",
    "\n",
    "print(\"-----------Train----------\")\n",
    "predict(model_name, train_data)\n",
    "\n",
    "print(\"-----------Test----------\")\n",
    "predict(model_name, test_data)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Train----------\n",
      "\n",
      "Metrics\n",
      "AUC: 0.99\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99    140413\n",
      "         1.0       0.94      0.64      0.76      9585\n",
      "\n",
      "    accuracy                           0.97    149998\n",
      "   macro avg       0.96      0.82      0.87    149998\n",
      "weighted avg       0.97      0.97      0.97    149998\n",
      "\n",
      "-----------Test----------\n",
      "\n",
      "Metrics\n",
      "AUC: 0.90\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.97    140597\n",
      "         1.0       0.70      0.33      0.45      9403\n",
      "\n",
      "    accuracy                           0.95    150000\n",
      "   macro avg       0.83      0.66      0.71    150000\n",
      "weighted avg       0.94      0.95      0.94    150000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = load_processed_data()\n",
    "\n",
    "model_name = \"LightGbmV1_hyperparemeter_optimization_14_06_2024_v3.pickle\"\n",
    "\n",
    "print(\"-----------Train----------\")\n",
    "predict(model_name, train_data)\n",
    "\n",
    "print(\"-----------Test----------\")\n",
    "predict(model_name, test_data)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Train----------\n",
      "\n",
      "Metrics\n",
      "AUC: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.96      0.98    140413\n",
      "         1.0       0.60      1.00      0.75      9585\n",
      "\n",
      "    accuracy                           0.96    149998\n",
      "   macro avg       0.80      0.98      0.87    149998\n",
      "weighted avg       0.97      0.96      0.96    149998\n",
      "\n",
      "-----------Test----------\n",
      "\n",
      "Metrics\n",
      "AUC: 0.89\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.96    140597\n",
      "         1.0       0.41      0.64      0.50      9403\n",
      "\n",
      "    accuracy                           0.92    150000\n",
      "   macro avg       0.69      0.79      0.73    150000\n",
      "weighted avg       0.94      0.92      0.93    150000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = load_processed_data()\n",
    "\n",
    "model_name = \"LightGbmV1_best.pickle\"\n",
    "\n",
    "print(\"-----------Train----------\")\n",
    "predict(model_name, train_data)\n",
    "\n",
    "print(\"-----------Test----------\")\n",
    "predict(model_name, test_data)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Train----------\n",
      "\n",
      "Metrics\n",
      "AUC: 0.99\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99    140413\n",
      "         1.0       0.94      0.64      0.76      9585\n",
      "\n",
      "    accuracy                           0.97    149998\n",
      "   macro avg       0.96      0.82      0.87    149998\n",
      "weighted avg       0.97      0.97      0.97    149998\n",
      "\n",
      "-----------Test----------\n",
      "\n",
      "Metrics\n",
      "AUC: 0.90\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.97    140597\n",
      "         1.0       0.70      0.33      0.45      9403\n",
      "\n",
      "    accuracy                           0.95    150000\n",
      "   macro avg       0.83      0.66      0.71    150000\n",
      "weighted avg       0.94      0.95      0.94    150000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = load_processed_data()\n",
    "\n",
    "model_name = \"LightGbmV2_best.pickle\"\n",
    "\n",
    "print(\"-----------Train----------\")\n",
    "predict(model_name, train_data)\n",
    "\n",
    "print(\"-----------Test----------\")\n",
    "predict(model_name, test_data)\n",
    "\n",
    "None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
